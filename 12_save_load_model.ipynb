{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60000179-7be3-406c-be8a-af4783358410",
   "metadata": {},
   "source": [
    "#  Saving & Loading Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a1d82-2a08-4833-b6e1-17b121c3664e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29a223-a2d3-4cbf-90f4-9dc0ba1ec880",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size    = 784 #28 x 28 = 784\n",
    "hidden_size   = 100\n",
    "num_classes   = 10\n",
    "learning_rate = 0.001\n",
    "#images have size of 28 x 28\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "batch_size    = 100\n",
    "\n",
    "training_dataset = torchvision.datasets.MNIST(root='./data', train=True , transform = transforms.ToTensor(),download=True )\n",
    "test_dataset     = torchvision.datasets.MNIST(root='./data', train=False, transform = transforms.ToTensor(),download=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=batch_size,  shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=test_dataset,     batch_size=batch_size,  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cdcf02-ccf2-4642-b196-5653c5969e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear( input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))  # input   + activation \n",
    "        output = self.fc2(x)        # outout\n",
    "        return output\n",
    "\n",
    "\n",
    "mlp_model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a741eb4-7587-432f-96c8-b12e23f5dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e8b53-6e59-42f9-b345-3b80a5ddbc3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1: Saving & Loading Entire Model\n",
    "    A common PyTorch convention is to save models using either a .pt or .pth file extension**\n",
    "\n",
    "- ### Save:\n",
    "    \n",
    "    torch.save(model, PATH)\n",
    "\n",
    ">Saves a serialized object to disk. This function uses **Python’s pickle** utility for serialization. Models, tensors, and dictionaries of all kinds of objects can be saved using this function.\n",
    " \n",
    "- ### Load:\n",
    "    \n",
    "    model = torch.load(PATH)\n",
    "    model.eval()\n",
    " \n",
    "> Uses pickle’s unpickling facilities to deserialize pickled object files to memory. This function also facilitates the device to load the data into\n",
    "\n",
    "> you must call model.eval(), It is a kind of switch for some specific layers/parts (dropout and batch normalization layers) of the model that behave differently during training and inference (evaluating) time, Failing to do this will yield inconsistent inference results.\n",
    ">\n",
    "> The common practice for evaluating/validation is using torch.no_grad() in pair with model.eval() to turn off gradients computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff4240-259c-44e4-bc95-0d9f761e1620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = \"mlp_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eeed92-6ba1-4059-b72a-a004476c7473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(mlp_model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e98fe7-62ff-40f4-bef1-e1446cebed77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_model = torch.load(PATH)\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fdefa5-f69d-4b69-aaee-9c6ca5b0af91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for param in loaded_model.parameters():\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e18610-e809-4b97-a6a8-b8fe52001434",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2:  Saving & Loading Trained Model for Inference\n",
    "\n",
    ">When saving a model for inference, it is only necessary to save the trained model’s learned parameters.\n",
    "\n",
    "\n",
    "\n",
    "- ### What is a state_dict?\n",
    ">In PyTorch, the learnable parameters (i.e. weights and biases) of an torch.nn.Module model are contained in the model’s parameters (accessed with model.parameters()). \n",
    "\n",
    ">A state_dict is simply a Python dictionary object that maps each layer to its parameter tensor. Note that only layers with learnable parameters (convolutional layers, linear layers, etc.) and registered buffers (batchnorm’s running_mean) have entries in the model’s state_dict. \n",
    "\n",
    ">Optimizer objects (torch.optim) also have a state_dict, which contains information about the optimizer’s state, as well as the hyperparameters used.\n",
    "\n",
    "## torch.nn.Module.load_state_dict: \n",
    ">Loads a model’s parameter dictionary using a deserialized **state_dict**.\n",
    ">\n",
    "- ### Save:\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "- ### Load:\n",
    "    model = torch.load_state_dict(torch.load(PATH))\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c69f61-c5e5-44c6-aba6-bca75594cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear( input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))  # input   + activation \n",
    "        output = self.fc2(x)        # outout\n",
    "        return output\n",
    "\n",
    "\n",
    "mlp_model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(),lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03e174-d9ee-459a-b850-9fc583ca8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs    = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        \n",
    "        #forward\n",
    "        pred_labels = mlp_model(images)\n",
    "        l = loss(pred_labels, labels)\n",
    "        #backward\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)% 100 ==0:\n",
    "            print(f'epoch: {epoch+1}/{num_epochs}, step {i+1}/{len(train_loader)}, loss = {l.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5faa15-4133-4204-a371-773ec00f71b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = \"trained_model.pth\"\n",
    "torch.save(mlp_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b16e4-a0f6-412a-9f0d-88bddd077ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(mlp_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9267ebaf-cc90-4420-ab0c-20bd610d7177",
   "metadata": {},
   "source": [
    ">Notice that the load_state_dict() function takes a dictionary object, NOT a path to a saved object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80523bc8-652a-43ce-96b7-0c499e597289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trained_loaded_model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "trained_loaded_model.load_state_dict(torch.load(PATH))\n",
    "trained_loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d9986a-3c3a-4228-8f42-b74de464c4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for param in trained_loaded_model.parameters():\n",
    "#     print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac072427-39d1-4515-908a-890b409257a0",
   "metadata": {},
   "source": [
    "#  3: Saving & Loading a General Checkpoint for Inference and/or Resuming Training\n",
    "    When saving a general checkpoint, to be used for either inference or resuming training, you must save more than just the model’s state_dict. It is important to also save the optimizer’s state_dict, as this contains buffers and parameters that are updated as the model trains. Other items that you may want to save are the epoch you left off on, the latest recorded training loss, external torch.nn.Embedding layers, etc. As a result, such a checkpoint is often 2~3 times larger than the model alone.\n",
    "loss = 0.0851\n",
    "### Save:\n",
    "   >\n",
    ">torch.save({\n",
    "   >\n",
    ">            'epoch': epoch,\n",
    "   >\n",
    ">            'model_state_dict': model.state_dict(),\n",
    "   >\n",
    ">            'optimizer_state_dict': optimizer.state_dict(),\n",
    "   >\n",
    ">            'loss': loss,\n",
    "   >\n",
    ">            ...\n",
    "   >\n",
    ">            }, PATH)\n",
    "\n",
    "### Load:\n",
    "   >\n",
    ">  model = TheModelClass(*args, **kwargs)\n",
    "   >\n",
    ">  optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "   >\n",
    ">  checkpoint = torch.load(PATH)\n",
    "   >\n",
    ">  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "   >\n",
    ">  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "   >\n",
    ">  epoch = checkpoint['epoch']\n",
    "   >\n",
    ">  loss = checkpoint['loss']\n",
    "   >\n",
    ">  model.eval()  - or - model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5434a-3a9c-42db-b9e8-ef37ba8f8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear( input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))  # input   + activation \n",
    "        output = self.fc2(x)        # outout\n",
    "        return output\n",
    "\n",
    "mlp_model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(),lr=learning_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0e91a-19b7-4e52-8992-253aaf98ad0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(mlp_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21dd2c-a3bc-4afc-bf09-24817aa3aa77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33979df-3205-47da-8959-8b72b934f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs    = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        \n",
    "        #forward\n",
    "        pred_labels = mlp_model(images)\n",
    "        l = loss(pred_labels, labels)\n",
    "        #backward\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1)% 100 ==0:\n",
    "            print(f'epoch: {epoch+1}/{num_epochs}, step {i+1}/{len(train_loader)}, loss = {l.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaee9a0-0114-42c5-ba68-271d542fa880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint ={\n",
    "            'epoch': num_epochs,\n",
    "            'model_state_dict': mlp_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }\n",
    "PATH = 'checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466a785-1194-4ef0-b2a4-e8f7882c312a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save( checkpoint, PATH )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37803237-a20d-4b84-97d9-726263a3d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_checkpoint = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e68197-2b30-41bd-966b-12b2d28f3ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a7e093-dee6-4398-93fd-89d66736b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b74269-9f09-482b-9437-76f1aa522cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=0)\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322a454b-c9d3-4bdb-847f-5ffae96bab22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da7c8c3-4ed7-4f17-8f0e-65d9c6a2c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7738a3f-4699-4e70-a0d5-e29b334c1edb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4: Saving & Loading Model Across Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d295b4c-9344-40a5-b3b5-20a956f9170e",
   "metadata": {},
   "source": [
    "### 4.1- Save on GPU, Load on CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed6bbe-394c-4b89-8e30-8d4a69fab44d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the device to 'cuda' for GPU\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Creating an instance of the model with 6 input features\n",
    "model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Saving the model's state dictionary to a specified path\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2da1b4-2cb0-4e17-aa27-722b26534ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the device to 'cpu'\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Creating a new instance of the model with 6 input features\n",
    "model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "\n",
    "# Loading the saved state dictionary into the model\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "\n",
    "# Moving the model to the target device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761969e1-c52c-407a-b7b1-e221fdaee461",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2- Save on GPU, Load on GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e2261-8e6e-4dae-94f0-660da395e109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the device to 'cuda' for GPU\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Creating an instance of the model with 6 input features and moving it to the GPU\n",
    "model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Saving the model's state dictionary to a specified path\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8358423-d988-46e5-a0d5-2c6fbb68a28a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the device to 'cuda' for GPU\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Creating a new instance of the model with 6 input features\n",
    "model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loading the saved state dictionary into the model\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# Moving the model to the GPU\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60a322-b372-4be3-b198-eaf88c27869a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.3- Save on CPU, Load on GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3796ae24-90db-41ad-af1a-be4030a35eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the device to 'cpu'\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Creating an instance of the model with 6 input features and moving it to the CPU\n",
    "model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "\n",
    "# Saving the model's state dictionary to a specified path\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840bcdd0-894a-485c-b057-13674398b95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting the device to 'cuda' for GPU\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# Creating a new instance of the model with 6 input features\n",
    "model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "\n",
    "# Loading the saved state dictionary into the model and mapping it to GPU\n",
    "model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))\n",
    "\n",
    "# Moving the model to the GPU\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f01d2-5c15-49eb-8400-38994700a5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9494d-950f-440e-9345-72f5f340ed67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
